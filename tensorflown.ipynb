{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf0078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Paso 1: Preparación de los datos\n",
    "data = [\n",
    "    (0, 169), (1, 157), (2, 114), (3, 101), (4, 101), (5, 104), (6, 77), (7, 83), (8, 62), (9, 68), (10, 59),\n",
    "    (11, 58), (12, 32), (13, 37), (14, 38), (15, 24), (16, 26), (17, 24), (18, 22), (19, 15), (20, 19), (21, 13),\n",
    "    (22, 9), (23, 9), (24, 3), (25, 9), (26, 6), (27, 8), (28, 10), (29, 3), (30, 7), (31, 5), (32, 3), (33, 2),\n",
    "    (34, 1), (35, 2), (36, 6), (37, 2), (38, 4), (40, 2), (42, 3), (44, 1), (46, 1), (47, 1), (48, 1), (51, 1),\n",
    "    (52, 1), (53, 1), (57, 1), (63, 1), (65, 1)\n",
    "]\n",
    "\n",
    "sequence = []\n",
    "for number, count in data:\n",
    "    sequence.extend([number] * count)\n",
    "\n",
    "sequence = np.array(sequence)\n",
    "\n",
    "# Paso 2: Preparación de secuencias de entrada y salida\n",
    "seq_length = 10  # Longitud de la secuencia\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(sequence) - seq_length):\n",
    "    x.append(sequence[i:i+seq_length])\n",
    "    y.append(sequence[i+seq_length])\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Paso 3: División en conjuntos de entrenamiento y prueba\n",
    "train_size = int(0.8 * len(x))\n",
    "train_x, test_x = x[:train_size], x[train_size:]\n",
    "train_y, test_y = y[:train_size], y[train_size:]\n",
    "\n",
    "# Paso 4: Creación del modelo de lenguaje recurrente\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(len(data), 10, input_length=seq_length),\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(len(data), activation='softmax')\n",
    "])\n",
    "\n",
    "# Paso 5: Compilación y entrenamiento del modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=20, batch_size=64)\n",
    "\n",
    "# Paso 6: Evaluación del modelo\n",
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "# Paso 7: Generación de texto\n",
    "seed_sequence = sequence[:seq_length]\n",
    "generated_sequence = list(seed_sequence)\n",
    "\n",
    "num_words_to_generate = 100\n",
    "\n",
    "for _ in range(num_words_to_generate):\n",
    "    encoded_seed = np.array([seed_sequence])\n",
    "    predicted_probs = model.predict(encoded_seed)[0]\n",
    "    predicted_id = np.random.choice(len(predicted_probs), p=predicted_probs)\n",
    "    generated_sequence.append(predicted_id)\n",
    "    seed_sequence = generated_sequence[-seq_length:]\n",
    "\n",
    "generated_sequence = np.array\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
